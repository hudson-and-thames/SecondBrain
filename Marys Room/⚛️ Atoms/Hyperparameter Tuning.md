# Hyperparameter Tuning
In [machine learning](https://en.wikipedia.org/wiki/Machine_learning "Machine learning"), **hyperparameter optimization** or tuning is the problem of choosing a set of optimal [hyperparameters](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning) "Hyperparameter (machine learning)") for a learning algorithm. A hyperparameter is a [parameter](https://en.wikipedia.org/wiki/Parameter "Parameter") whose value is used to control the learning process. By contrast, the values of other parameters (typically node weights) are learned.

The same kind of machine learning model can require different constraints, weights or learning rates to generalize different data patterns. These measures are called hyperparameters, and have to be tuned so that the model can optimally solve the machine learning problem. Hyperparameter optimization finds a tuple of hyperparameters that yields an optimal model which minimizes a predefined [loss function](https://en.wikipedia.org/wiki/Loss_function "Loss function") on given independent data. The objective function takes a tuple of hyperparameters and returns the associated loss. [Cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics) "Cross-validation (statistics)") is often used to estimate this generalization performance.

---
Topics :: [[Machine Learning]] 
Reference :: [[Model evaluation]]
Type :: #atom
Creator :: Dennis
TAF ::
Date :: 2022-07-07 15:04